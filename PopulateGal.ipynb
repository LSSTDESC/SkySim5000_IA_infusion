{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5957a-08d6-4ac9-aa38-d449c59bc6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Joachim Harnois-Deraps, with inputs from Ben Giblin on the galaxy populatio algorithm, \n",
    "# and Nan Li on some lensing subroutines \n",
    "# Code illustrating extraction of shear from Mira Titan/SkySim5000 healpix maps\n",
    "\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import random\n",
    "import input\n",
    "\n",
    "SkySim=False\n",
    "HACCY1=True\n",
    "\n",
    "seed=2 #seed = 0,1,2\n",
    "nshells=106 #nshells=19,50,106\n",
    "IC=150     #IC=150,195\n",
    "\n",
    "#Choose Nz:\n",
    "#SRD:\n",
    "#nz_filename='./nz_sources_srd_5bins.txt'\n",
    "\n",
    "#Stage-IV_Euclid\"\n",
    "nz_filename='./Euclid_dndz_fu08_bin1-5.dat'\n",
    "\n",
    "# the number of galaxies per square arcminute to extract\n",
    "gpam = 0.6\n",
    "#gpam = 2.6    #LSST, per tomo bin\n",
    "#gpam = 1.493  #KiDS tomo4\n",
    "#gpam = 1.830  #KiDS tomo3\n",
    "#gpam = 1.856  #KiDS tomo2\n",
    "#gpam = 2.354  #KiDS tomo1\n",
    "\n",
    "print('assigning %f gal/arcmin**2' % gpam)\n",
    "\n",
    "# the number of galaxies to extract in the octant\n",
    "ngal = int(gpam * (4.*np.pi/8.)*(180./np.pi)**2. *3600.)\n",
    "print('for a total of %i galaxies' % ngal)\n",
    "\n",
    "# The NSIDE value of the shear and weight maps\n",
    "if(SkySim):\n",
    "    nside = 8192\n",
    "if(HACCY1):\n",
    "    nside = 4096\n",
    "\n",
    "npix = 12*nside**2\n",
    "pix_size = np.sqrt(4.*np.pi*(180./np.pi*60)**2/npix)\n",
    "print('pixel size of shear maps is %f arcmin per side' % pix_size)\n",
    "\n",
    "def IndexToDeclRa(index):\n",
    "        theta,phi=hp.pixelfunc.pix2ang(nside,index,nest=False)\n",
    "        return np.degrees(np.pi/2. - theta),np.degrees(phi)\n",
    "    \n",
    "def GetNz(nz_filename,tomobin):\n",
    "        print(\"Reading in N(z) from tomobin  %d\" % tomobin)\n",
    "        data = np.loadtxt(nz_filename, usecols=(0,tomobin))\n",
    "        z_array = data[:,0]\n",
    "        pdz = data[:,1]\n",
    "        dz = z_array[41] - z_array[40]\n",
    "        n_zbins = np.size(pdz)\n",
    "\n",
    "        # Normalise:\n",
    "        pdz = pdz/sum(pdz)/dz\n",
    "        print(\"Check normalisation: sum n(z) dz = \",sum(pdz)*dz)\n",
    "        print(\"Mean redshift = \", np.dot(pdz,z_array)*dz)\n",
    "        return n_zbins,z_array, pdz,dz\n",
    "    \n",
    "def AssignRedshifts(n_zbins,pdz,dz):\n",
    "\n",
    "        #construct cumulative distribution\n",
    "        cumul_dist = np.zeros(n_zbins)\n",
    "\n",
    "        for z_bin in range(0,n_zbins):\n",
    "            cumul_dist[z_bin] = sum(pdz[0:z_bin+1])/sum(pdz)\n",
    "            #print(z_array[z_bin], pdz[z_bin], cumul_dist[z_bin])\n",
    "\n",
    "        print('Got cumul dist')\n",
    "        \n",
    "        #--------------------------------\n",
    "        #draw the galaxies from this n(z) (This routine may take a few seconds to execute)\n",
    "        spec_z = np.zeros(ngal)\n",
    "\n",
    "        for gal in range(0,ngal):\n",
    "            gal_bin = 0\n",
    "            ran = random.uniform(0, 1)\n",
    "            for z_bin in range(0,n_zbins):\n",
    "                #print ran, cumul_dist[z_bin]\n",
    "                if ran < cumul_dist[z_bin]:\n",
    "                    gal_bin = z_bin\n",
    "                    break\n",
    "            \n",
    "            #randomize distribution within that bin\n",
    "            ran2 = random.uniform(0,1)*dz\n",
    "            spec_z[gal] = z_array[gal_bin]+ran2\n",
    "            #print( gal, gal_bin, z_array[gal_bin], spec_z[gal],z_array[gal_bin+1])\n",
    "\n",
    "\n",
    "        print('Assigned redshift to these galaxies')\n",
    "        print('-----------------------------------')\n",
    "        return spec_z\n",
    "    \n",
    "def PlotNz(spec_z,z_array,dz,pdz,tomobin):\n",
    "    \n",
    "        import matplotlib.pyplot as plt\n",
    "        # the histogram of the data\n",
    "        n, bins, patches = plt.hist(spec_z, 60, density=True, facecolor='g',alpha=0.75)\n",
    "        plt.xlabel('z')\n",
    "        plt.ylabel('n(z)')\n",
    "        #plt.text(60, .025, r'tomobin 1')\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.plot(z_array+dz/2, pdz)\n",
    "        if tomobin==1: \n",
    "            plt.xlim(0, 0.5)\n",
    "            plt.ylim(0, 4,0)\n",
    "        elif tomobin==2: \n",
    "            plt.xlim(0.45, 0.85)\n",
    "            plt.ylim(0, 5,0)\n",
    "        elif tomobin==3: \n",
    "            plt.xlim(0.65, 1.05)\n",
    "            plt.ylim(0, 5,0)\n",
    "        elif tomobin==4: \n",
    "            plt.xlim(0.95, 1.45)\n",
    "            plt.ylim(0, 5,0)\n",
    "        elif tomobin==5: \n",
    "            plt.xlim(1.3, 3.10)\n",
    "            plt.ylim(0, 5,0)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "def PopulateHACCY1(spec_z,tomobin,gpam,IC,seed,nshells):\n",
    "\n",
    "        import healsparse\n",
    "        import random\n",
    "        import os\n",
    "\n",
    "        nside_c = 32\n",
    "        \n",
    "        #IC=195\n",
    "        path = '/global/cscratch1/sd/xuod/HOS_sims/L845/HACC'+str(IC)+'/'\n",
    "        #nshells=19\n",
    "        #seed=0\n",
    "        what1='gamma1'\n",
    "        what2='gamma2'\n",
    "        nzs='kappa_zsnapshots'\n",
    "\n",
    "        #find galaxies between shear planes i and j, load the maps, interpolate, loop over next maps\n",
    "\n",
    "        # Selection population option:\n",
    "        # 1 = randomly choose pixels from the unmasked section of the map\n",
    "        # 2 = randomly generate angular coords from the unmasked octant (more accurate than OPTION 1)\n",
    "        # 3 = load mass sheet and populate the galaxies following a linear biasing scheme\n",
    "        OPTION=2\n",
    "\n",
    "\n",
    "        zfile=np.loadtxt(\"z2ts_HACCY1_\"+str(nshells)+\".txt\")\n",
    "        #snaplist = zfile[1:107,1].astype(int)\n",
    "        shell_list=np.flip(zfile[:,0])\n",
    "        z_list=np.flip(zfile[:,1]) \n",
    "        z_list_front=np.flip(zfile[:,2])\n",
    "        z_list_back=np.flip(zfile[:,3])\n",
    "        n_slices = np.size(z_list)\n",
    "        #print(zfile)\n",
    "        #print(z_list)\n",
    "\n",
    "        ngal_cur = np.zeros(n_slices, dtype=int)\n",
    "\n",
    "        ngal_analyzed = 0\n",
    "        weight_flag = 0\n",
    "        recycle_map_flag = 0\n",
    "\n",
    "        # Loop over all planes, starting from high redshift towards z=0\n",
    "        for plane in range(0,n_slices):\n",
    "        #for plane in range(0,n_slices):\n",
    "\n",
    "            print('starting analysis of plane %i' % plane)\n",
    "\n",
    "            z_back = z_list_back[plane]\n",
    "            z_front = z_list_front[plane]\n",
    "\n",
    "            print('z_lo - z_mid -  z_hi =',   z_front, z_list[plane], z_back)\n",
    "            gal_cur = np.where(np.logical_and(spec_z>z_front, spec_z<=z_back))\n",
    "            ngal_cur[plane] = np.size(gal_cur)\n",
    "            if ngal_cur[plane] == 0:\n",
    "                print('no galaxies here, loop to next plane')\n",
    "            else:\n",
    "                print('found %s galaxies between z=%f and z=%f' % (ngal_cur[plane], z_front, z_back))\n",
    "                ngal_analyzed = ngal_analyzed+ngal_cur[plane]\n",
    "                #\n",
    "                if ngal_cur[plane-1] >0:\n",
    "                    print(\"Found consecutive planes not empty, recycle planes to save IO:\")\n",
    "                    recycle_map_flag = 1\n",
    "                    # Uncomment the above to enable recycling\n",
    "\n",
    "                #Interpolate from shear maps onto redshift of the halo:\n",
    "                #! dz1 (dz2) is fractional distance to plane behind (in front)\n",
    "                #\n",
    "                dz1 = z_back - spec_z[gal_cur]\n",
    "                if plane == n_slices -1:\n",
    "                    dz2 = spec_z[gal_cur]\n",
    "                else: \n",
    "                    dz2 = spec_z[gal_cur] - z_front\n",
    "                #\n",
    "                dz1 = dz1/(dz1 + dz2)\n",
    "                dz2 = 1. - dz1\n",
    "                #\n",
    "                #  ishell=0 -> z=0 in Cyrille's maps, contrary to the naming from the HACC snapshots.\n",
    "                ishell = int(shell_list[plane]) \n",
    "\n",
    "                #print(z_front, z_back, spec_z[gal_cur], dz1, dz2)\n",
    "\n",
    "\n",
    "                if weight_flag == 0:\n",
    "                    print('reading weight file')\n",
    "                    weight_flag = 1\n",
    "                    print(\"Reading in weight map for HACC-Y1\")\n",
    "                    #hpmap_weight = hp.fitsfunc.read_map('../../FullSky_weight.fits', field=0,nest=False, partial=False, hdu=1, h=False, verbose=True, memmap=True)\n",
    "                    hpmap_weight = hp.fitsfunc.read_map('../../FullSky_weight_4096.fits', field=0,nest=False, partial=False, hdu=1, h=False, verbose=True, memmap=True)\n",
    "                    #\n",
    "                    # masking - not really necessary here, but just in case it is useful for something else.\n",
    "                    unmask = np.where(hpmap_weight > 0)[0]\n",
    "                    #\n",
    "                if recycle_map_flag==0:\n",
    "                    print(\"Reading in shear 1 back (zs = %f)\" % z_back)\n",
    "                    print(\"Reading in shear 2 back (zs = %f)\" % z_back)\n",
    "\n",
    "                    a = healsparse.HealSparseMap.read(os.path.join(path, f'shells_z{nshells}_subsampleauto_groupiso/{nzs}/gamma1_hacc_nz{ishell}_nside4096_seed{seed}.fits'))\n",
    "                    hpmap_g1_back = a.generate_healpix_map()\n",
    "                    print(\"loaded gamma1\")\n",
    "\n",
    "                    a = healsparse.HealSparseMap.read(os.path.join(path, f'shells_z{nshells}_subsampleauto_groupiso/{nzs}/gamma2_hacc_nz{ishell}_nside4096_seed{seed}.fits'))\n",
    "                    hpmap_g2_back = a.generate_healpix_map()\n",
    "                    print(\"loaded gamma2\")                                    \n",
    "\n",
    "                    #a = healsparse.HealSparseMap.read(os.path.join(path, f'shells_z{nshells}_subsampleauto_groupiso/{nzs}/kappa_hacc_nz{plane}_nside4096_seed{seed}.fits'))\n",
    "                    #hpmap_kappa_back = a.generate_healpix_map()\n",
    "                    #print(\"loaded kappa\")                                    \n",
    "\n",
    "                    #hp.orthview(hpmap_g1_back**2 + hpmap_g2_back**2, rot=(35, 20),half_sky=True, min=-0.1, max=0.1, title=None)\n",
    "                    #hp.graticule()\n",
    "                    #hp.orthview(hpmap_kappa_back, rot=(35, 20),half_sky=True, min=-0.1, max=0.1, title=None)\n",
    "                    #hp.graticule()\n",
    "\n",
    "                else:\n",
    "                    print(\"Recycling map to reduce IO:, zs = %f was already loaded, now used as back plane\" % z_back)\n",
    "                    hpmap_g1_back= hpmap_g1_front\n",
    "                    hpmap_g2_back= hpmap_g2_front\n",
    "                    #hpmap_kappa_back= hpmap_kappa_front\n",
    "\n",
    "                    recycle_map_flag = 0\n",
    "                #\n",
    "                print(\"Reading in shear 1/2/kappa front (zs = %f)\" % z_front)\n",
    "\n",
    "                if z_front==0:\n",
    "                    hpmap_g1_front = hpmap_g1_back - hpmap_g1_back\n",
    "                    hpmap_g2_front = hpmap_g2_back - hpmap_g2_back\n",
    "                    #hpmap_kappa_front = hpmap_kappa_back - hpmap_kappa_back\n",
    "\n",
    "                else:\n",
    "\n",
    "                    a = healsparse.HealSparseMap.read(os.path.join(path, f'shells_z{nshells}_subsampleauto_groupiso/{nzs}/gamma1_hacc_nz{ishell-1}_nside4096_seed{seed}.fits'))\n",
    "                    hpmap_g1_front = a.generate_healpix_map()\n",
    "                    print(\"loaded gamma1\")\n",
    "\n",
    "                    a = healsparse.HealSparseMap.read(os.path.join(path, f'shells_z{nshells}_subsampleauto_groupiso/{nzs}/gamma2_hacc_nz{ishell-1}_nside4096_seed{seed}.fits'))\n",
    "                    hpmap_g2_front = a.generate_healpix_map()\n",
    "                    print(\"loaded gamma2\")                                    \n",
    "\n",
    "                    #a = healsparse.HealSparseMap.read(os.path.join(path, f'shells_z{nshells}_subsampleauto_groupiso/{nzs}/kappa_hacc_nz{plane+1}_nside4096_seed{seed}.fits'))\n",
    "                    #hpmap_kappa_front = a.generate_healpix_map()\n",
    "                    #print(\"loaded kappa\")                                    \n",
    "\n",
    "\n",
    "                # Got shear and kappa maps \n",
    "\n",
    "\n",
    "                #-------------\n",
    "                if(OPTION==1):\n",
    "                    # OPTION 1:\n",
    "                    # randomly choose pixels from the unmasked section of the map\n",
    "                    print('Getting the indicies for %s random unmasked galaxies in Mira Titan' %ngal_cur[plane])\n",
    "                    #idx = np.random.choice(unmask, int(ngal_cur[plane]))\n",
    "                    #print idx\n",
    "                    #\n",
    "                    # get the ra and dec of these pixels\n",
    "                    #dec,ra= IndexToDeclRa( idx )\n",
    "                    #\n",
    "                    # get the shear maps at these pixels\n",
    "                    #shear1_pix_front = hpmap_g1_front[idx]\n",
    "                    #shear2_pix_front = hpmap_g2_front[idx]\n",
    "                    #shear1_pix_back = hpmap_g1_back[idx]\n",
    "                    #shear2_pix_back = hpmap_g2_back[idx]\n",
    "                    #\n",
    "                    #print shear1_pix_front, shear1_pix_back, dz1, dz2, shear1_pix_front*dz1 + shear1_pix_back*dz2\n",
    "                    #print shear2_pix_front, shear2_pix_back, dz1, dz2, shear2_pix_front*dz1 + shear2_pix_back*dz2\n",
    "                    #\n",
    "                    #\n",
    "                    #np.savetxt('./MyProject/MT_nz_delta05_LSST_lmax20000_%sGpAM_zfront%s_z_back%s.asc'%(gpam,z_front, z_back), np.c_[ra, dec, shear1_pix_front*dz1 + shear1_pix_back*dz2, shear2_pix_front*dz1 + shear2_pix_back*dz2,spec_z[gal_cur]])\n",
    "                    #np.savetxt('./MyProject/MT_nz_LSST_lmax20000_%sGpAM_zfront%s_z_back%s_recycle.asc'%(gpam,z_front, z_back), np.c_[ra, dec, shear1_pix_front*dz1 + shear1_pix_back*dz2, shear2_pix_front*dz1 + shear2_pix_back*dz2, hpmap_weight[idx],spec_z[gal_cur]])\n",
    "                    #np.savetxt('./MyProject/MT_nz_LSST_lmax20000_%sGpAM_zfront%s_z_back%s_dz_flip.asc'%(gpam,z_front, z_back), np.c_[ra, dec, shear1_pix_front*dz2 + shear1_pix_back*dz1, shear2_pix_front*dz2 + shear2_pix_back*dz1,hpmap_weight[idx] spec_z[gal_cur]])\n",
    "                    #np.savetxt('./MyProject/MT_nz_LSST_lmax5000%sGpAM_zfront%s_z_back%s.asc'%(gpam,z_front, z_back), np.c_[ra, dec, shear1_pix_front*dz1 + shear1_pix_back*dz2, shear2_pix_front*dz1 + shear2_pix_back*dz2,spec_z[gal_cur]])\n",
    "                    #np.savetxt('./MyProject/MT_nz_KiDS_01_09_lmax32768%sGpAM_nside%s.asc'%(gpam,nside), np.c_[ra, dec, hpmap_g1[idx], hpmap_g2[idx], hpmap_weight[idx] ])\n",
    "\n",
    "                    #-------------\n",
    "                elif(OPTION==2):\n",
    "                    # OPTION 2:\n",
    "                    # randomly generate angular coords from the unmasked octant, and use healpy interpolation\n",
    "                    # function to get the shear at these locations\n",
    "                    dec,ra = IndexToDeclRa( unmask )\n",
    "                    ra_rand = np.random.uniform( np.min(ra), np.max(ra), ngal_cur[plane])\n",
    "                    #\n",
    "                    # This preferentially generate theta at large angles; therefore dec at small angles, near the equator.\n",
    "                    # (if you randomly uniformly generate dec, you end up with all your points at the pole,\n",
    "                    # and the CF looks wacky).\n",
    "                    dec_rand = ( np.pi/2. - np.arccos(np.random.uniform( 0., 1., ngal_cur[plane])) ) * 180./np.pi\n",
    "                    #\n",
    "                    shear1_pix_front = hp.get_interp_val( hpmap_g1_front, (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "                    shear2_pix_front = hp.get_interp_val( hpmap_g2_front, (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "                    #kappa_pix_front = hp.get_interp_val( hpmap_kappa_front, (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "\n",
    "                    shear1_pix_back  = hp.get_interp_val( hpmap_g1_back,  (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "                    shear2_pix_back  = hp.get_interp_val( hpmap_g2_back,  (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "                    #kappa_pix_back = hp.get_interp_val( hpmap_kappa_back, (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "\n",
    "\n",
    "                     #\n",
    "                    # Save a shear catalogue in standard format to be read by Athena\n",
    "                    outname = '../../../HACC-Y1/GalCat/StageIV_nz/HACC'+str(IC)+'/V0/seed'+np.str(seed)+'/GalCat_tomo'+np.str(tomobin)+'_plane'+np.str(plane)+'_nshells'+str(nshells)+'_'+np.str(gpam)+'GpAM_RA_Dec_g1_g2_w_z.asc'\n",
    "                    #outname = input.GalDir+'StageIV_nz/GalCat_tomo'+np.str(tomobin)+'_plane'+np.str(plane)+'_'+np.str(gpam)+'GpAM_RA_Dec_g1_g2_w_kappa.asc'\n",
    "\n",
    "                    print(\"Wrinting\",outname)\n",
    "\n",
    "                    # given ra=np.degrees(phi), e2 DOES NOT NEED FLIPPING.\n",
    "                    #np.savetxt(outname, np.c_[ra_rand, dec_rand, shear1_pix_front*dz1 + shear1_pix_back*dz2, shear2_pix_front*dz1 + shear2_pix_back*dz2, np.ones(ngal_cur[plane]),spec_z[gal_cur],kappa_pix_front*dz1 + kappa_pix_back*dz2 ])\n",
    "                    np.savetxt(outname, np.c_[ra_rand, dec_rand, shear1_pix_front*dz1 + shear1_pix_back*dz2, shear2_pix_front*dz1 + shear2_pix_back*dz2, np.ones(ngal_cur[plane]),spec_z[gal_cur] ])\n",
    "\n",
    "                    #-------------\n",
    "                elif(OPTION==3):\n",
    "                    #---------\n",
    "                    # OPTION 3:\n",
    "                    # Assign galaxies at positions that trace the underlying dark matter map:\n",
    "                    # Based on s script from Pierre Burger, PhD Candidate, Bonn University, (2022)\n",
    "\n",
    "                    #path_in = 'IA-infusion/SkySim5000/density/'\n",
    "                    #fname = path_in+\"density_map_\"+str(snaplist[plane])+\"_dens_allsky.npy\"\n",
    "                    #print(\"opening \", fname) \n",
    "                    #hpmap_density = np.load(fname)\n",
    "                    #print(\"Got density file!\")\n",
    "                    #hp.mollview(hpmap_density[unmask], nest=False)\n",
    "                    #plt.show()      \n",
    "                    #must apply Octant mask\n",
    "                    path_in=\"/global/cfs/cdirs/lsst/groups/CS/mass_sheets/\"\n",
    "                    print(\"loading delta map:\")\n",
    "                    fname = path_in+'density_map_'+np.str(snaplist[plane])+'_dens.bin'\n",
    "                    print('Working on file '+fname)\n",
    "                    tmp = np.fromfile(fname,'<f')\n",
    "\n",
    "                    # Format is nested, order into ring in order to use alm2maps transforms\n",
    "                    # and degrade NSIDE \n",
    "                    #print(\"NSIDE_orig=\", hp.get_nside(tmp))\n",
    "                    #binmap=hp.pixelfunc.ud_grade(tmp, 4096, pess=False, order_in='NESTED', order_out='RING', power=None, dtype=None)\n",
    "                    #print(\"NSIDE_new=\", hp.get_nside(binmap))\n",
    "\n",
    "                    # Or reorder, keeping all full NSIDE resolution\n",
    "                    hpmap_density = hp.reorder(tmp, n2r = True)\n",
    "                    del tmp\n",
    "\n",
    "                    print(\"Got RING-ordered input map\")\n",
    "                    # Normalize the maps correctly:       \n",
    "                    mean_map = (np.mean(hpmap_density)*8.0) # no factor of 8.0 since we have full sky data here\n",
    "                    hpmap_density /= mean_map \n",
    "                    hpmap_density -= 1\n",
    "                    print(\"Transformed from number count to over-density map\")\n",
    "\n",
    "                    hp.mollview(hpmap_density, nest=False)\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "                    bias=1.0\n",
    "                    pixel_area_arcmin2=pix_size**2          \n",
    "                    octant_area_arcmin2 = np.sum(hpmap_weight)*pixel_area_arcmin2\n",
    "                    gpam_z= ngal_cur[plane]/octant_area_arcmin2\n",
    "                    random.seed(1)\n",
    "\n",
    "                    n_bar = gpam_z*pixel_area_arcmin2\n",
    "                    #construct this equation here: n=n_bar*(1+bias*hpmap_density)   \n",
    "                    hpmap_density*=bias\n",
    "                    hpmap_density+=1.0\n",
    "                    hpmap_density*=n_bar\n",
    "                    print(\"Transformed from over-density to galaxy density map\")\n",
    "\n",
    "                    negative_n=np.where(hpmap_density<0)[0]\n",
    "                    hpmap_density[negative_n]=0            \n",
    "                    print(\"Enforced positivity everywhere\")\n",
    "\n",
    "                    SGD = np.random.poisson(hpmap_density)\n",
    "                    print(\"Poisson sampled the map\")\n",
    "\n",
    "                    # Construct the pixel catalogues\n",
    "                    max_gal = np.max(SGD)\n",
    "                    print(\"max Ngal per pixel = \", max_gal)\n",
    "                    pixel=np.where(SGD>0)[0]\n",
    "                    positive_SGD = SGD[pixel]\n",
    "                    print(pixel.shape,positive_SGD.shape)\n",
    "                    max_gal = np.max(SGD)\n",
    "                    print(\"Max number of gal per pixel = \", max_gal)\n",
    "                    for i in range(1,max_gal):\n",
    "                        pixel_new=np.where(SGD>i)[0]\n",
    "                        print(\"Found \",np.shape(pixel_new), \"pixels with more than \",i,\"galaxies in it.\")\n",
    "                        print(\"Adding these to the pixel data vector\")\n",
    "                        pixel = np.hstack([pixel,pixel_new])\n",
    "                        print(pixel.shape)\n",
    "\n",
    "                    # Poisson sampling means you might endup with slightly more or less galaxies than the true deterministic input\n",
    "                    # given by ngal_cur[plane]. \n",
    "\n",
    "                    #If too much candidates, randomly downsample pixels:\n",
    "                    if(len(pixel)>=ngal_cur[plane]):\n",
    "                        pixel=pixel[np.random.choice(len(pixel), size=ngal_cur[plane], replace=False)]\n",
    "                    else:    \n",
    "                    #If not enough candidates, randomly downsample the redshifts \n",
    "                        gal_tmp = gal_cur[0]\n",
    "                        down_sampl_pix = np.random.choice(len(gal_tmp), size=len(pixel), replace=False)\n",
    "                        gal_tmp = gal_tmp[down_sampl_pix]\n",
    "                        dz1 = dz1[down_sampl_pix]\n",
    "                        dz2 = dz2[down_sampl_pix]\n",
    "\n",
    "                        gal_cur = gal_tmp\n",
    "\n",
    "\n",
    "                    dec_rand,ra_rand = IndexToDeclRa(pixel)\n",
    "                    # optional: randomly shift the position within the pixels\n",
    "                    # for this, use the healpy.boundaries() function, with step=1, which\n",
    "                    # returns the 4 corners of the pixel boundaries. These can be used to \n",
    "                    # sample the pixel area.\n",
    "\n",
    "                    shear1_pix_front = hp.get_interp_val( hpmap_g1_front, (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "                    shear2_pix_front = hp.get_interp_val( hpmap_g2_front, (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "                    #kappa_pix_front = hp.get_interp_val( hpmap_kappa_front, (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "\n",
    "                    shear1_pix_back  = hp.get_interp_val( hpmap_g1_back,  (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "                    shear2_pix_back  = hp.get_interp_val( hpmap_g2_back,  (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "                    #kappa_pix_back = hp.get_interp_val( hpmap_kappa_back, (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "\n",
    "\n",
    "                     #\n",
    "                    # Save a shear catalogue in standard format to be read by Athena/Treecorr\n",
    "                    outname = input.GalDir+'StageIV_nz/GalCat_tomo'+np.str(tomobin)+'_plane'+np.str(plane)+'_'+np.str(gpam)+'GpAM_RA_Dec_g1_g2_w_linear_bias.asc'\n",
    "                    print(\"Wrinting\",outname)\n",
    "                    np.savetxt(outname, np.c_[ra_rand, dec_rand, shear1_pix_front*dz1 + shear1_pix_back*dz2, shear2_pix_front*dz1 + shear2_pix_back*dz2, np.ones(len(pixel)),spec_z[gal_cur] ])\n",
    "                    print(\"Done\")\n",
    "\n",
    "                    del SGD \n",
    "                    del hpmap_density\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(\"***************************\")\n",
    "        print(\"Done writing all catalogues\")\n",
    "        print(\"***************************\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b4837-b04e-48f0-962a-36df46e5cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run pipeline:\n",
    "    \n",
    "# The tomographic bin\n",
    "for tomobin in range(1,6):\n",
    "    \n",
    "    print(\"**************************\")\n",
    "    print(\"Processing tomo bin\",tomobin)\n",
    "    print(\"**************************\")\n",
    "    \n",
    "    # 1- Read N(z)    \n",
    "    n_zbins,z_array,pdz,dz = GetNz(nz_filename,tomobin)\n",
    "\n",
    "    # 2- Assign Redshifts\n",
    "    spec_z = AssignRedshifts(n_zbins,pdz,dz)\n",
    "\n",
    "    # 3- Plot input n(z) vs galaxy histogram\n",
    "    PlotNz(spec_z,z_array,dz,pdz,tomobin)\n",
    "\n",
    "    # 4- Make catalogue\n",
    "    PopulateHACCY1(spec_z,tomobin,gpam,IC,seed,nshells)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fc36c6-c47c-46aa-8413-419164a9aa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate catalogues:\n",
    "import os\n",
    "\n",
    "if(SkySim):\n",
    "    print('Concatenating SkySim5000 plane catalogues')\n",
    "    #os.system(\"for tomo in {1..1}; do echo 'working on tomo'$tomo; ls -l   /global/homes/j/jharno/IA-infusion/SkySim5000/GalCat/StageIV_nz/*tomo$tomo*0.6GpAM*; done\")\n",
    "    #os.system(\"for tomo in {1..1}; do cat   /global/homes/j/jharno/IA-infusion/SkySim5000/GalCat/StageIV_nz/*tomo$tomo*0.6GpAM* > /global/homes/j/jharno/IA-infusion/SkySim5000/GalCat/StageIV_nz/GalCat_tomo$tomo'_All_0.6GpAM_RA_Dec_g1_g2_w_z.asc'; done\")\n",
    "    os.system(\"for tomo in {5..5}; do echo 'working on tomo'$tomo; ls -l   /global/homes/j/jharno/IA-infusion/SkySim5000/GalCat/StageIV_nz/*tomo$tomo*0.06GpAM_RA_Dec_g1_g2_w_linear_bias.asc; done\")\n",
    "    os.system(\"for tomo in {5..5}; do cat   /global/homes/j/jharno/IA-infusion/SkySim5000/GalCat/StageIV_nz/*tomo$tomo*0.06GpAM_RA_Dec_g1_g2_w_linear_bias.asc > /global/homes/j/jharno/IA-infusion/SkySim5000/GalCat/StageIV_nz/V1/GalCat_tomo$tomo'_All_0.06GpAM_RA_Dec_g1_g2_w_z_linear_bias.asc'; done\")\n",
    "\n",
    "    \n",
    "if(HACCY1):\n",
    "    print('Concatenating HACC plane catalogues')\n",
    "    #GpAM='0.06':\n",
    "    #os.system(\"let tomo=5; ls -l   /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/V0/seed0/*tomo$tomo*nshells19_0.06GpAM*\")\n",
    "    #os.system(\"let tomo=5; cat   /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/V0/seed0/*tomo$tomo*nshells19_0.06GpAM* > /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/V0/seed0/GalCat_tomo$tomo'_All_nshells19_0.06GpAM_RA_Dec_g1_g2_w_z.asc'\")\n",
    "\n",
    "    #GpAM='0.6':\n",
    "    #os.system(\"let tomo=5; ls -l   /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/V0/seed0/*tomo$tomo*nshells106_0.6GpAM*\")\n",
    "    #os.system(\"let tomo=5; cat   /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/V0/seed0/*tomo$tomo*nshells106_0.6GpAM* > /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/V0/seed0/GalCat_tomo$tomo'_All_nshells106_0.6GpAM_RA_Dec_g1_g2_w_z.asc'\")\n",
    "    #os.system(\"for tomo in {1..5}; do  ls -l   /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/HACC150/V0/seed0/*tomo$tomo*nshells106_0.06GpAM*; done\")\n",
    "    #os.system(\"for tomo in {1..5}; do cat   /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/HACC150/V0/seed0/*tomo$tomo*nshells106_0.06GpAM* > /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/HACC150/V0/seed0/GalCat_tomo$tomo'_All_nshells106_0.06GpAM_RA_Dec_g1_g2_w_z.asc'; done\")\n",
    "    #os.system(\"for tomo in {1..5}; do ls -l   /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/HACC150/V0/seed2/*tomo$tomo*nshells50_0.6GpAM* ; done\"); \n",
    "    #os.system(\"for tomo in {1..5}; do cat   /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/HACC150/V0/seed2/*tomo$tomo*nshells50_0.6GpAM* > /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/HACC150/V0/seed2/GalCat_tomo$tomo'_All_nshells50_0.6GpAM_RA_Dec_g1_g2_w_z.asc'; done\")\n",
    "    os.system(\"let seed=2; let nshells=106; for tomo in {1..5}; do ls -l /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/HACC150/V0/seed$seed/*tomo$tomo*plane*nshells$nshells'_0.6GpAM'* ; done\"); \n",
    "    os.system(\"let seed=2; let nshells=106; for tomo in {1..5}; do cat   /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/HACC150/V0/seed$seed/*tomo$tomo*plane*nshells$nshells'_0.6GpAM'* > /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/HACC150/V0/seed$seed/GalCat_tomo$tomo'_All_nshells'$nshells'_0.6GpAM_RA_Dec_g1_g2_w_z.asc'; done\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a75b93-0137-4c13-93e6-cf496a463e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up catalogues for boundary effects, where shear is sometimes -1e30...\n",
    "# Must run after concatenating the plane catalogues\n",
    "#seed=1\n",
    "if(HACCY1):\n",
    "    path='/global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/HACC150/V0/seed'+str(seed)+'/'\n",
    "    #GpAM='0.6'\n",
    "    for tomo in range(1,6):\n",
    "        fname_in='GalCat_tomo'+str(tomo)+'_All_nshells'+str(nshells)+'_'+GpAM+'GpAM_RA_Dec_g1_g2_w_z.asc'\n",
    "        fname_out='GalCat_tomo'+str(tomo)+'_All_nshells'+str(nshells)+'_'+GpAM+'GpAM_RA_Dec_g1_g2_w_z_good.asc'\n",
    "\n",
    "        GalCat = np.loadtxt(path+fname_in)\n",
    "        Good_cat = GalCat[GalCat[:,3]>-1]\n",
    "        np.savetxt(path+fname_out,Good_cat)\n",
    "        Bad_cat = GalCat[GalCat[:,3]<-1]\n",
    "        print(\"Removed \"+str(np.shape(Bad_cat)[0])+\" bad galaxies\")\n",
    "        print('Cleaned GalCat for tomo',tomo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f2cf0-a76d-40cd-b9d8-42e16e0b0bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove temporary products\n",
    "#os.system(\"ls -l   /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/HACC150/V0/seed1/*plane*\")\n",
    "#os.system(\"cat     /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/HACC150/V0/seed1/*plane*\")\n",
    "# Might not always work on jupyter notebook, as it involves too much data being erased, clean up in terminal instead...\n",
    "\n",
    "# clean up the un-good galaxy products:\n",
    "os.system(\"let seed=2;rm -v   /global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/HACC150/V0/seed$seed/*g1_g2_w_z.asc\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ba937-e566-4f80-806b-bc55a3cd4254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SkySim5000:\n",
    "if(SkySim):\n",
    "\n",
    "    import random\n",
    "\n",
    "\n",
    "    #find galaxies with shear planes i and j, load the maps, interpolate, loop over next maps\n",
    "    #z_list = np.loadtxt('list_zs.dat')\n",
    "\n",
    "    # Selection population option:\n",
    "    # 1 = randomly choose pixels from the unmasked section of the map, only good for flat sky.\n",
    "    # 2 = randomly generate angular coords from the unmasked octant (more accurate than OPTION 1)\n",
    "    # 3 = load mass sheet and populate the galaxies following a linear biasing scheme\n",
    "    OPTION=3\n",
    "    b_TA=2.0\n",
    "\n",
    "    zfile=np.loadtxt(\"z2ts.txt\",delimiter=',')\n",
    "    snaplist = np.flip(zfile[1:58,1]).astype(int)\n",
    "    z_list=np.flip(zfile[1:58,0])\n",
    "\n",
    "    n_slices = np.size(z_list)\n",
    "    #print(zfile)\n",
    "    #print(z_list)\n",
    "\n",
    "    ngal_cur = np.zeros(n_slices, dtype=int)\n",
    "\n",
    "    ngal_analyzed = 0\n",
    "    weight_flag = 0\n",
    "    recycle_map_flag = 0\n",
    "\n",
    "    # Loop over all planes, starting from high redshift towards z=0\n",
    "    for plane in range(36,37):\n",
    "    #for plane in range(0,n_slices):\n",
    "\n",
    "        print('starting analysis of plane %i' % plane)\n",
    "\n",
    "        #--------------------------------------\n",
    "        # Get redshifts of the source planes:\n",
    "        z_back = z_list[plane]\n",
    "        if plane == n_slices-1:\n",
    "            z_front = 0.0\n",
    "        else:\n",
    "            z_front = z_list[plane+1]\n",
    "        print('z_lo - z_hi =', z_front, z_back)\n",
    "        #--------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "        gal_cur = np.where(np.logical_and(spec_z>z_front, spec_z<=z_back))\n",
    "        ngal_cur[plane] = np.size(gal_cur)\n",
    "        if ngal_cur[plane] == 0:\n",
    "            print('no galaxies here, loop to next plane')\n",
    "        else:\n",
    "            print('found %s galaxies between z=%f and z=%f' % (ngal_cur[plane], z_front, z_back))\n",
    "            ngal_analyzed = ngal_analyzed+ngal_cur[plane]\n",
    "            #\n",
    "            if ngal_cur[plane-1] >0:\n",
    "                print(\"Found consecutive planes not empty, recycle planes to save IO:\")\n",
    "                recycle_map_flag = 1\n",
    "                # Uncomment the above to enable recycling\n",
    "\n",
    "            #Interpolate from shear maps onto redshift of the halo:\n",
    "            #! dz1 (dz2) is fractional distance to plane behind (in front)\n",
    "            #\n",
    "            dz1 = z_back - spec_z[gal_cur]\n",
    "            if plane == n_slices -1:\n",
    "                dz2 = spec_z[gal_cur]\n",
    "            else: \n",
    "                dz2 = spec_z[gal_cur] - z_front\n",
    "            #\n",
    "            dz1 = dz1/(dz1 + dz2)\n",
    "            dz2 = 1. - dz1\n",
    "            #\n",
    "            #print(z_front, spec_z[gal_cur], z_back, dz1, dz2)\n",
    "\n",
    "            if weight_flag == 0:\n",
    "                print('reading weight file')\n",
    "                weight_flag = 1\n",
    "                print(\"Reading in weight map for OuterRim/Mira Titan\")\n",
    "                hpmap_weight = hp.fitsfunc.read_map('../../FullSky_weight.fits', field=0,nest=False, partial=False, hdu=1, h=False, verbose=True, memmap=True)\n",
    "                #\n",
    "                # masking - not really necessary here, but just in case it is useful for something else.\n",
    "                unmask = np.where(hpmap_weight > 0)[0]\n",
    "                #\n",
    "            if recycle_map_flag==0:\n",
    "                print(\"Reading in shear 1 back (zs = %f)\" % z_back)\n",
    "                print(\"Reading in shear 2 back (zs = %f)\" % z_back)\n",
    "\n",
    "                fname1 = \"../../shear/\"+str(\"{:5.4f}\".format(z_back))+\"gamma1.npy\"\n",
    "                fname2 = \"../../shear/\"+str(\"{:5.4f}\".format(z_back))+\"gamma2.npy\"\n",
    "                #fname3 = input.kappaDir+np.str(\"{:5.4f}\".format(z_back))+\"kappa.npy\"\n",
    "\n",
    "                hpmap_g1_back = np.load(fname1)\n",
    "                print(\"loaded gamma1\")\n",
    "\n",
    "                hpmap_g2_back = np.load(fname2)\n",
    "                print(\"loaded gamma2\")                                    \n",
    "\n",
    "                #hpmap_kappa_back = np.load(fname3)\n",
    "                #print(\"loaded kappa\")                                    \n",
    "\n",
    "\n",
    "            else:\n",
    "                print(\"Recycling map to reduce IO:, zs = %f was already loaded, now used as back plane\" % z_back)\n",
    "                hpmap_g1_back= hpmap_g1_front\n",
    "                hpmap_g2_back= hpmap_g2_front\n",
    "                #hpmap_kappa_back= hpmap_kappa_front\n",
    "\n",
    "                recycle_map_flag = 0\n",
    "            #\n",
    "            print(\"Reading in shear 1/2/kappa front (zs = %f)\" % z_front)\n",
    "\n",
    "            if z_front==0:\n",
    "                hpmap_g1_front = hpmap_g1_back - hpmap_g1_back\n",
    "                hpmap_g2_front = hpmap_g2_back - hpmap_g2_back\n",
    "                #hpmap_kappa_front = hpmap_kappa_back - hpmap_kappa_back\n",
    "\n",
    "            else:\n",
    "                fname1 = \"../../shear/\"+str(\"{:5.4f}\".format(z_front))+\"gamma1.npy\"\n",
    "                fname2 = \"../../shear/\"+str(\"{:5.4f}\".format(z_front))+\"gamma2.npy\"\n",
    "                #fname3 = input.kappaDir+np.str(\"{:5.4f}\".format(z_front))+\"kappa.npy\"\n",
    "\n",
    "\n",
    "                hpmap_g1_front = np.load(fname1)\n",
    "                print(\"loaded gamma1\")\n",
    "\n",
    "                hpmap_g2_front = np.load(fname2)\n",
    "                print(\"loaded gamma2\")                                    \n",
    "\n",
    "                #hpmap_kappa_front = np.load(fname3)\n",
    "                #print(\"loaded kappa\")                                    \n",
    "\n",
    "\n",
    "            # Got shear and kappa maps \n",
    "\n",
    "\n",
    "            #-------------\n",
    "            if(OPTION==1):\n",
    "                # OPTION 1:\n",
    "                # randomly choose pixels from the unmasked section of the map\n",
    "                # Only good for flat sky.\n",
    "                print('Getting the indicies for %s random unmasked galaxies' %ngal_cur[plane])\n",
    "                idx = np.random.choice(unmask, int(ngal_cur[plane]))\n",
    "                #print idx\n",
    "                #\n",
    "                # get the ra and dec of these pixels\n",
    "                dec,ra= IndexToDeclRa( idx )\n",
    "                #\n",
    "                # get the shear maps at these pixels\n",
    "                shear1_pix_front = hpmap_g1_front[idx]\n",
    "                shear2_pix_front = hpmap_g2_front[idx]\n",
    "                shear1_pix_back = hpmap_g1_back[idx]\n",
    "                shear2_pix_back = hpmap_g2_back[idx]\n",
    "                #\n",
    "                np.savetxt('./MyProject/MT_nz_LSST_lmax5000%sGpAM_zfront%s_z_back%s.asc'%(gpam,z_front, z_back), np.c_[ra, dec, shear1_pix_front*dz1 + shear1_pix_back*dz2, shear2_pix_front*dz1 + shear2_pix_back*dz2,spec_z[gal_cur]])\n",
    "\n",
    "                #-------------\n",
    "            elif(OPTION==2):\n",
    "                # OPTION 2:\n",
    "                # randomly generate angular coords from the unmasked octant, and use healpy interpolation\n",
    "                # function to get the shear at these locations\n",
    "                dec,ra = IndexToDeclRa( unmask )\n",
    "                ra_rand = np.random.uniform( np.min(ra), np.max(ra), ngal_cur[plane])\n",
    "                #\n",
    "                # This preferentially generate theta at large angles; therefore dec at small angles, near the equator.\n",
    "                # (if you randomly uniformly generate dec, you end up with all your points at the pole,\n",
    "                # and the CF looks wacky).\n",
    "                dec_rand = ( np.pi/2. - np.arccos(np.random.uniform( 0., 1., ngal_cur[plane])) ) * 180./np.pi\n",
    "                #\n",
    "                shear1_pix_front = hp.get_interp_val( hpmap_g1_front, (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "                shear2_pix_front = hp.get_interp_val( hpmap_g2_front, (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "                #kappa_pix_front = hp.get_interp_val( hpmap_kappa_front, (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "\n",
    "                shear1_pix_back  = hp.get_interp_val( hpmap_g1_back,  (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "                shear2_pix_back  = hp.get_interp_val( hpmap_g2_back,  (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "                #kappa_pix_back = hp.get_interp_val( hpmap_kappa_back, (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "\n",
    "\n",
    "                 #\n",
    "                # Save a shear catalogue in standard format to be read by Athena\n",
    "                #outname = \"../../GalCat/\"+'StageIV_nz/GalCat_tomo'+np.str(tomobin)+'_plane'+np.str(plane)+'_'+np.str(gpam)+'GpAM_RA_Dec_g1_g2_w.asc'\n",
    "                outname = '../../GalCat/SRD-Y1/random_pos/GalCat_tomo'+np.str(tomobin)+'_plane'+np.str(plane)+'_'+np.str(gpam)+'GpAM_RA_Dec_g1_g2_w_z.asc'\n",
    "                #outname = input.GalDir+'StageIV_nz/GalCat_tomo'+np.str(tomobin)+'_plane'+np.str(plane)+'_'+np.str(gpam)+'GpAM_RA_Dec_g1_g2_w_kappa.asc'\n",
    "\n",
    "                print(\"Wrinting\",outname)\n",
    "\n",
    "                # given ra=np.degrees(phi), e2 DOES NOT NEED FLIPPING.\n",
    "                #np.savetxt(outname, np.c_[ra_rand, dec_rand, shear1_pix_front*dz1 + shear1_pix_back*dz2, shear2_pix_front*dz1 + shear2_pix_back*dz2, np.ones(ngal_cur[plane]),spec_z[gal_cur],kappa_pix_front*dz1 + kappa_pix_back*dz2 ])\n",
    "                np.savetxt(outname, np.c_[ra_rand, dec_rand, shear1_pix_front*dz1 + shear1_pix_back*dz2, shear2_pix_front*dz1 + shear2_pix_back*dz2, np.ones(ngal_cur[plane]),spec_z[gal_cur] ])\n",
    "\n",
    "                #-------------\n",
    "            elif(OPTION==3):\n",
    "                #---------\n",
    "                # OPTION 3:\n",
    "                # Assign galaxies at positions that trace the underlying dark matter map:\n",
    "                # Based on s script from Pierre Burger, PhD Candidate, Bonn University, (2022)\n",
    "    \n",
    "                path_in=\"/global/cfs/cdirs/lsst/groups/CS/mass_sheets/\"\n",
    "                print(\"loading delta map:\")\n",
    "                fname = path_in+'density_map_'+np.str(snaplist[plane])+'_dens.bin'\n",
    "                print('Working on file '+fname)\n",
    "                tmp = np.fromfile(fname,'<f')\n",
    "\n",
    "                # Format is nested, reorder pixels into ring in order to use alm2maps transforms\n",
    "                # and potentially degrade NSIDE \n",
    "                #print(\"NSIDE_orig=\", hp.get_nside(tmp))\n",
    "                #binmap=hp.pixelfunc.ud_grade(tmp, 4096, pess=False, order_in='NESTED', order_out='RING', power=None, dtype=None)\n",
    "                #print(\"NSIDE_new=\", hp.get_nside(binmap))\n",
    "\n",
    "                # Or reorder, keeping all full NSIDE resolution\n",
    "                hpmap_density = hp.reorder(tmp, n2r = True)\n",
    "                del tmp\n",
    "\n",
    "                print(\"Got RING-ordered input map\")\n",
    "                # Normalize the maps correctly:       \n",
    "                mean_map = (np.mean(hpmap_density)*8.0) # factor of 8.0 since we have octant\n",
    "                hpmap_density /= mean_map \n",
    "                hpmap_density -= 1\n",
    "                hpmap_density*=hpmap_weight # Applied mask\n",
    "                print(\"Transformed from number count to over-density map, with mask\")\n",
    "\n",
    "               \n",
    "                bias=b_TA\n",
    "                pixel_area_arcmin2=pix_size**2          \n",
    "                octant_area_arcmin2 = np.sum(hpmap_weight)*pixel_area_arcmin2\n",
    "                gpam_z_per_arcmin2= ngal_cur[plane]/octant_area_arcmin2\n",
    "                random.seed(1)\n",
    "\n",
    "                n_bar = gpam_z_per_arcmin2*pixel_area_arcmin2 # mean number of galaxies per pixel\n",
    "                #------------------------\n",
    "                #construct this equation: n(x)=n_bar*(1+bias*delta(x))   \n",
    "                #------------------------\n",
    "                \n",
    "                hpmap_density*=bias\n",
    "                hpmap_density+=1.0\n",
    "                hpmap_density*=n_bar\n",
    "                hpmap_density*=hpmap_weight # Applied mask\n",
    "\n",
    "                print(\"Transformed from over-density to galaxy density map\")\n",
    "\n",
    "                negative_n=np.where(hpmap_density<0)[0]\n",
    "                hpmap_density[negative_n]=0            \n",
    "                print(\"Enforced positivity everywhere\")\n",
    "\n",
    "                SGD = np.random.poisson(hpmap_density)\n",
    "                print(\"Poisson sampled the map\")\n",
    "\n",
    "                # Construct the catalogues\n",
    "                max_gal = np.max(SGD)\n",
    "                print(\"max Ngal per pixel = \", max_gal)\n",
    "                pixel=np.where(SGD>0)[0]\n",
    "                positive_SGD = SGD[pixel]\n",
    "                print(pixel.shape,positive_SGD.shape)\n",
    "                max_gal = np.max(SGD)\n",
    "                print(\"Max number of gal per pixel = \", max_gal)\n",
    "                for i in range(1,max_gal):\n",
    "                    pixel_new=np.where(SGD>i)[0]\n",
    "                    print(\"Found \",np.shape(pixel_new), \"pixels with more than \",i,\"galaxies in it.\")\n",
    "                    print(\"Adding these to the pixel data vector\")\n",
    "                    pixel = np.hstack([pixel,pixel_new])\n",
    "                    print(pixel.shape)\n",
    "\n",
    "                # Poisson sampling means you might endup with slightly more or less galaxies than the true deterministic input\n",
    "                # given by ngal_cur[plane]. \n",
    "\n",
    "                #If too much candidates, randomly downsample pixels:\n",
    "                if(len(pixel)>=ngal_cur[plane]):\n",
    "                    pixel=pixel[np.random.choice(len(pixel), size=ngal_cur[plane], replace=False)]\n",
    "                else:    \n",
    "                #If not enough candidates, randomly downsample the redshifts \n",
    "                    gal_tmp = gal_cur[0]\n",
    "                    down_sampl_pix = np.random.choice(len(gal_tmp), size=len(pixel), replace=False)\n",
    "                    gal_tmp = gal_tmp[down_sampl_pix]\n",
    "                    dz1 = dz1[down_sampl_pix]\n",
    "                    dz2 = dz2[down_sampl_pix]\n",
    "\n",
    "                    gal_cur = gal_tmp\n",
    "                    \n",
    "                dec_rand,ra_rand = IndexToDeclRa(pixel)\n",
    "\n",
    "                \n",
    "                #----------\n",
    "                #hp.mollview(hpmap_density, nest=False)\n",
    "                #plt.show()\n",
    "                #----------\n",
    "                lonra = [0, 2]\n",
    "                latra = [0, 1]\n",
    "                hp.cartview(hpmap_density,\n",
    "                    cbar=True, lonra=lonra, latra=latra,\n",
    "                    nest=False,\n",
    "                    title=\" \",\n",
    "                    # min=-10, max=0,\n",
    "                    cmap=plt.cm.coolwarm,\n",
    "                    norm=None, unit='delta')\n",
    "                #plt.show()\n",
    "                                \n",
    "                hp.projscatter(ra_rand,dec_rand,lonlat=True,marker=(5, 2),c='tab:orange',alpha=0.5)\n",
    "                plt.show()\n",
    " \n",
    "                \n",
    "                # optional: randomly shift the position within the pixels\n",
    "                # for this, use the healpy.boundaries() function, with step=1, which\n",
    "                # returns the 4 corners of the pixel boundaries. These can be used to \n",
    "                # sample the pixel area.\n",
    "\n",
    "                shear1_pix_front = hp.get_interp_val( hpmap_g1_front, (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "                shear2_pix_front = hp.get_interp_val( hpmap_g2_front, (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "                #kappa_pix_front = hp.get_interp_val( hpmap_kappa_front, (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "\n",
    "                shear1_pix_back  = hp.get_interp_val( hpmap_g1_back,  (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "                shear2_pix_back  = hp.get_interp_val( hpmap_g2_back,  (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "                #kappa_pix_back = hp.get_interp_val( hpmap_kappa_back, (90.-dec_rand)*np.pi/180., ra_rand*np.pi/180., nest=False )\n",
    "\n",
    "\n",
    "                 #\n",
    "                # Save a shear catalogue in standard format to be read by Athena/Treecorr\n",
    "                #outname = '../../GalCat/StageIV_nz/V1/GalCat_tomo'+np.str(tomobin)+'_plane'+np.str(plane)+'_'+np.str(gpam)+'GpAM_RA_Dec_g1_g2_w_linear_bias.asc'\n",
    "                #outname = '../../GalCat/StageIV_nz/V1/GalCat_tomo'+np.str(tomobin)+'_plane'+np.str(plane)+'_'+np.str(gpam)+'GpAM_RA_Dec_g1_g2_w_linear_bias_bta2.asc'\n",
    "                #outname = '../../GalCat/SRD-Y1/V1/GalCat_tomo'+np.str(tomobin)+'_plane'+np.str(plane)+'_'+np.str(gpam)+'GpAM_RA_Dec_g1_g2_w_linear_bias_bta2.asc'\n",
    "                #outname = '../../GalCat/SRD-Y1/lin_bias_pos/GalCat_tomo'+np.str(tomobin)+'_plane'+np.str(plane)+'_'+np.str(gpam)+'GpAM_RA_Dec_g1_g2_w_linear_bias_bta1.asc'\n",
    "                outname = '../../GalCat/SRD-Y1/lin_bias_pos/GalCat_tomo'+np.str(tomobin)+'_plane'+np.str(plane)+'_'+np.str(gpam)+'GpAM_RA_Dec_g1_g2_w_linear_bias_bta2.asc'\n",
    "                print(\"Wrinting\",outname)\n",
    "                np.savetxt(outname, np.c_[ra_rand, dec_rand, shear1_pix_front*dz1 + shear1_pix_back*dz2, shear2_pix_front*dz1 + shear2_pix_back*dz2, np.ones(len(pixel)),spec_z[gal_cur] ])\n",
    "                print(\"Done\")\n",
    "\n",
    "                del SGD \n",
    "                del hpmap_density\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"***************************\")\n",
    "    print(\"Done writing all catalogues\")\n",
    "    print(\"***************************\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5901c94d-2219-478a-af85-1e3adad6fe3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1fb56f-a058-4c97-a8e6-ea86180ee78e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dae90c-495a-450b-9f9d-6072eb22fea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc36c8a6-f660-4054-b128-43b08fcb3ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224eba81-ecd2-406d-bbf2-616e9360b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise HACC-Y1 catalogue\n",
    "seed = 2\n",
    "GpAM='0.6'\n",
    "path='/global/homes/j/jharno/IA-infusion/HACC-Y1/GalCat/StageIV_nz/HACC150/V0/seed'+str(seed)+'/'\n",
    "\n",
    "for tomo in range(2,3):\n",
    "    fname_in='GalCat_tomo'+str(tomo)+'_All_nshells'+str(nshells)+'_'+GpAM+'GpAM_RA_Dec_g1_g2_w_z_good.asc'\n",
    "    GalCat = np.loadtxt(path+fname_in)\n",
    "    \n",
    "    hp.mollview()\n",
    "    hp.projscatter(GalCat[:,0],GalCat[:,1], lonlat=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b1ce05-00ca-4a39-b832-22dcc9b953c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plane=33\n",
    "fname = path_in+'density_map_'+np.str(snaplist[plane])+'_dens.bin'\n",
    "\n",
    "print('Working on file '+fname)\n",
    "tmp = np.fromfile(fname,'<f')\n",
    "\n",
    "# Format is nested, order into ring in order to use alm2maps transforms\n",
    "# and degrade NSIDE \n",
    "#print(\"NSIDE_orig=\", hp.get_nside(tmp))\n",
    "#binmap=hp.pixelfunc.ud_grade(tmp, 4096, pess=False, order_in='NESTED', order_out='RING', power=None, dtype=None)\n",
    "#print(\"NSIDE_new=\", hp.get_nside(binmap))\n",
    "\n",
    "# Or reorder, keeping all full NSIDE resolution\n",
    "hpmap_density = hp.reorder(tmp, n2r = True)\n",
    "del tmp\n",
    "hp.mollview(hpmap_density, nest=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931cb31c-7def-4248-aaed-8d670032478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise SkySim5000 catalogue\n",
    "lonra = [0, 2]\n",
    "latra = [0, 1]\n",
    "hp.cartview(hpmap_density,\n",
    "    cbar=True, lonra=lonra, latra=latra,\n",
    "    nest=False,\n",
    "    title=\" \",\n",
    "    # min=-10, max=0,\n",
    "    cmap=plt.cm.coolwarm,\n",
    "    norm=None, unit='delta')\n",
    "#plt.show()\n",
    "\n",
    "GpAM='0.06'\n",
    "path='/global/homes/j/jharno/IA-infusion/SkySim5000/GalCat/StageIV_nz/'\n",
    "\n",
    "\n",
    "\n",
    "for tomo in range(3,4):\n",
    "    fname_in='GalCat_tomo'+str(tomo)+'_plane33_'+GpAM+'GpAM_RA_Dec_g1_g2_w_linear_bias.asc'\n",
    "    GalCat = np.loadtxt(path+fname_in)\n",
    "    \n",
    "    #hp.mollview()\n",
    "    #hp.projscatter(GalCat[:,0],GalCat[:,1], lonlat=True)\n",
    "    #plt.show()\n",
    "    \n",
    "    #hp.cartview(lonra=lonra, latra=latra,\n",
    "    #            nest=False,\n",
    "    #            title=\" \",\n",
    "    #            norm=None, unit=None)\n",
    "    hp.projscatter(GalCat[:,0],GalCat[:,1],lonlat=True,marker=(5, 2),c='tab:orange',alpha=0.3)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76b7b1f-8780-46d3-b669-480eba674789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the mask file\n",
    "hpmap_weight = hp.fitsfunc.read_map('./IA-infusion/SkySim5000/FullSky_weight.fits', field=0,nest=False, partial=False, hdu=1, h=False, verbose=True, memmap=True)\n",
    "#\n",
    "# masking - not really necessary here, but just in case it is useful for something else.\n",
    "unmask = np.where(hpmap_weight > 0)[0]\n",
    "\n",
    "\n",
    "NSIDE=8192\n",
    "pixel_area_arcmin2 = hp.pixelfunc.nside2pixarea(nside=NSIDE)*(180*60/np.pi)**2\n",
    "octant_area_arcmin2 = sum(unmask)*pixel_area_arcmin2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85e2b35-510a-4cce-8314-f3188617e4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ceef0f-e9c2-40e8-8171-b6412419279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b50d3f7-2abb-47de-bbde-7c3ea6b55a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbfe49c-b7af-4f92-83c5-699b44a8aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec2e53-c714-4547-8f51-49be4634329e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a62dc-53a1-4702-8594-9633ff1215ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-python-dev",
   "language": "python",
   "name": "desc-python-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
